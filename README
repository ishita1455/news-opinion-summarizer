# Newspaper Opinion/Editorial Extraction & Summarization Pipeline

## Overview

This project implements a **fully automated pipeline** to process multiple English newspapers in PDF format. It:

1. Identifies pages containing **Opinion / Editorial sections**.
2. Extracts only those pages.
3. Merges the extracted pages into a **single consolidated PDF**.
4. Generates **summaries** of the extracted pages using an LLM (Groq).
5. Works seamlessly on **Windows and Linux** with minimal human intervention.

This pipeline is designed for efficiency, automation, and professional reporting of editorial content.

---

## Features

* **Automated page extraction** from PDFs using PyPDF2.
* **OCR fallback** for scanned PDFs with no text using Tesseract via `pytesseract`.
* **Keyword-based detection**: identifies Opinion, Editorial, and related sections.
* **Merged PDF output**: all relevant pages combined into a single file.
* **LLM Summarization**: generates concise summaries for each extracted page using Groq API.
* **Cross-platform compatibility**: works on Windows and Linux.
* **Logging**: detailed logging of processed pages, added pages, and any errors.

---

## Folder Structure

```
project-root/
│
├─ input_pdfs/           # Place all newspaper PDFs here
├─ output/               # Temporary processing (optional)
├─ final/                # Contains merged PDF and summaries
│   ├─ opinion_editorials_<timestamp>.pdf
│   ├─ summaries_<timestamp>.txt
│   └─ summaries_<timestamp>.md
├─ summarizer.py         # Main pipeline script
├─ setup_pipeline.sh     # Linux setup script
├─ README.md
└─ requirements.txt      # Optional Python dependencies
```

---

## Setup Instructions

### Linux

1. Clone the repository:

```bash
git clone <repo_url>
cd <repo_folder>
```

2. Run the setup script to install dependencies, Tesseract, and Poppler:

```bash
chmod +x setup_pipeline.sh
./setup_pipeline.sh
```

3. Enter your **Groq API Key** when prompted:

```bash
export GROQ_API_KEY="your_groq_api_key_here"
```

4. Run the pipeline:

```bash
source venv/bin/activate
python summarizer.py
```

---

### Windows

1. Install Python 3.10+ and virtual environment:

```powershell
python -m venv .venv
.\.venv\Scripts\activate
```

2. Install dependencies:

```powershell
pip install PyPDF2 pdf2image pytesseract groq
```

3. Install **Tesseract OCR** from [https://github.com/tesseract-ocr/tesseract](https://github.com/tesseract-ocr/tesseract) and add it to PATH.

4. Set the Groq API Key in PowerShell:

```powershell
$env:GROQ_API_KEY="your_groq_api_key_here"
```

5. Run the pipeline:

```powershell
python summarizer.py
```

---

## How It Works

1. **PDF Scanning**: Reads all PDFs in `input_pdfs/`.
2. **Text Extraction**: Uses PyPDF2 to extract text; OCR fallback for scanned pages.
3. **Keyword Detection**: Pages containing “opinion”, “editorial”, or similar keywords are selected.
4. **PDF Merging**: Extracted pages are combined into a single PDF.
5. **Summarization**: Text from extracted pages is summarized using Groq LLM in batches.
6. **Output**:

   * Merged PDF: `final/opinion_editorials_<timestamp>.pdf`
   * Summaries: `final/summaries_<timestamp>.txt` and `.md`

---

## Dependencies

* Python 3.10+
* PyPDF2
* pdf2image
* pytesseract
* Groq Python SDK
* Tesseract OCR (system-level)
* Poppler utils (for `pdf2image`)

---

## Logging

* All processed pages, added pages, and summaries are logged in `process.log`.
* Provides visibility for skipped pages, OCR usage, and API errors.

---

## Notes

* Batch summarization helps avoid rate limits and improves reliability.
* Pipeline is **cross-platform**; paths and OCR configurations adapt automatically.
* Merged PDFs include **only editorial content**, ensuring concise and focused outputs.


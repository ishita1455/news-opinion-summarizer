# ğŸ“° Newspaper Opinion/Editorial Extraction & Summarization Pipeline

## ğŸ“Œ Overview

This project implements a **fully automated pipeline** to process multiple English newspapers in PDF format. It:

1. Identifies pages containing **Opinion / Editorial sections**.
2. Extracts only those pages.
3. Merges extracted pages into a **single consolidated PDF**.
4. Generates **summaries** of the extracted content using an LLM (Groq).
5. Runs seamlessly on **Windows and Linux** with minimal human intervention.

This pipeline is designed for **efficiency, automation, and professional reporting** of editorial content.

---

## âœ¨ Features

* **Automated page extraction**: Uses PyPDF2 to extract relevant pages.
* **OCR fallback**: Handles scanned PDFs using Tesseract via `pytesseract`.
* **Keyword & header-based detection**: Finds *Opinion*, *Editorial*, *Views*, and related sections.
* **Merged PDF output**: Consolidates all relevant opinion/editorial pages into one file.
* **LLM summarization**: Generates concise summaries with Groq API.
* **Cross-platform compatibility**: Tested on Windows & Linux.
* **Robust logging**: Tracks processed files, extracted pages, and errors.

---

## âš™ï¸ Setup

### Prerequisites

* Python 3.10+
* [Poppler](https://github.com/oschwartz10612/poppler-windows) (for `pdf2image`)
* [Tesseract OCR](https://github.com/tesseract-ocr/tesseract)

### Installation

```bash
git clone https://github.com/ishita1455/news-opinion-summarizer.git
cd news-opinion-summarizer
python -m venv .venv
source .venv/bin/activate   # Linux / macOS
.venv\Scripts\activate      # Windows

pip install -r requirements.txt
```

### Set Groq API Key

```bash
export GROQ_API_KEY="your_api_key_here"   # Linux / macOS
$env:GROQ_API_KEY="your_api_key_here"     # Windows PowerShell
```

---

## ğŸš€ Usage

1. Place all input newspaper PDFs inside the **`input_pdfs/`** folder.
2. Run the pipeline:

   ```bash
   python summarizer.py
   ```
3. Outputs:

   * **final/opinion_editorials.pdf** â†’ merged editorial pages
   * **final/summaries.txt** â†’ plain text summaries
   * **final/summaries.md** â†’ markdown summaries

---

## ğŸ›  Example Workflow

```bash
Processing: The Hindu HD-19.pdf  
   -> Added page 10 (Editorial)  
   -> Added page 11 (Opinion)  
ğŸ“„ Merged PDF saved at: final/opinion_editorials.pdf  
ğŸ“ Summaries saved at: final/summaries.txt  
ğŸ“˜ Markdown summaries saved at: final/summaries.md  
```

---

## ğŸ“‚ Project Structure

```
news-opinion-summarizer/
â”‚â”€â”€ input_pdfs/              # Place input newspapers here
â”‚â”€â”€ output/                  # Temporary files
â”‚â”€â”€ final/                   # Final merged PDF + summaries
â”‚â”€â”€ summarizer.py            # Main pipeline
â”‚â”€â”€ requirements.txt         # Python dependencies
â”‚â”€â”€ README.md                # Project documentation
```

---

## ğŸ¯ Key Highlights

* Automated end-to-end extraction and summarization.
* Works with both **text-based and scanned PDFs**.
* Provides **quick insights** from lengthy newspapers.

